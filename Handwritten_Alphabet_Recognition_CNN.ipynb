{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten-Alphabet-Recognition-CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6AsvbDDeuPUjeqzqAbIfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimothyJan/Handwritten-Alphabet-Recognition-CNN/blob/main/Handwritten_Alphabet_Recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fv9j1A84vbwU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset for this project contains 372450 images of alphabets of 28Ã—2, all present in the form of a CSV file: \n",
        "<a href='https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format?resource=download'>Handwritten Character Recognition Dataset</a>"
      ],
      "metadata": {
        "id": "mv-l8iZZJSRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r\"A_Z Handwritten Data.csv\").astype('float32')\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "id": "9YGTIOoVvm5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "76672393-e259-4b52-cc6f-726dd4aace5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-11727d601b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"A_Z Handwritten Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'A_Z Handwritten Data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Split data into images and their corresponding labels.</h1>"
      ],
      "metadata": {
        "id": "X5PZM3T5JpAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing 'o' column from the labels\n",
        "X = data.drop('0',axis = 1)\n",
        "y = data['0']"
      ],
      "metadata": {
        "id": "kmxCb4-rvpg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Reshape the data in csv file to be displayed as an image.</h1>"
      ],
      "metadata": {
        "id": "xSYRHYnwJ1f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing datasets\n",
        "# display images as 28x28pixels, originally 784 columns of pixel data\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
        "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
        "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
        "print(\"Train data shape: \", train_x.shape)\n",
        "print(\"Test data shape: \", test_x.shape)"
      ],
      "metadata": {
        "id": "iCEyXP8FHPdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Map Integer values with characters.</h1>"
      ],
      "metadata": {
        "id": "mzIWUGKvJ71n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}"
      ],
      "metadata": {
        "id": "1F-DBh__HWZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Plot the number of alphabets in the dataset.</h1>"
      ],
      "metadata": {
        "id": "_YhQGACNJ_TB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_int = np.int0(y)\n",
        "count = np.zeros(26, dtype='int')\n",
        "for i in y_int:\n",
        "    count[i] +=1\n",
        "alphabets = []\n",
        "for i in word_dict.values():\n",
        "    alphabets.append(i)\n",
        "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
        "ax.barh(alphabets, count)\n",
        "plt.title('Distribution of Alphabet')\n",
        "plt.xlabel(\"Number of elements \")\n",
        "plt.ylabel(\"Alphabets\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4TZlvg4vHk9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Shuffle the data.</h1>"
      ],
      "metadata": {
        "id": "n6SxDHH-KFLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuff = shuffle(train_x[:100])\n",
        "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "axes = ax.flatten()\n",
        "for i in range(9):\n",
        "    _, shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
        "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s18D_OksHzFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Reshape the training & test dataset to be put in model.</h1>\n",
        "Using the method to_categorical(), a numpy array (or) a vector which has integers that represent different categories, can be converted into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data."
      ],
      "metadata": {
        "id": "RXfKBnUNKI8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "print(\"New shape of train data: \", train_X.shape)\n",
        "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
        "print(\"New shape of train data: \", test_X.shape)\n",
        "# Reshape the train & test image dataset so that they can be put in the model.\n",
        "# New shape of train data:  (297960, 28, 28, 1)\n",
        "# New shape of train data:  (74490, 28, 28, 1)"
      ],
      "metadata": {
        "id": "FG37aigCIOjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Reshape the training and test dataset so that it can be put in the model.</h1>\n",
        "The single float values are converted to categorical values. This is done as the CNN model takes input of labels & generates the output as a vector of probabilities."
      ],
      "metadata": {
        "id": "NHLUDD8FJJRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of train labels: \", train_yOHE.shape)\n",
        "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of test labels: \", test_yOHE.shape)"
      ],
      "metadata": {
        "id": "wiIIl1-5Ihm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>CNN stands for Convolutional Neural Networks that are used to extract the features of the images using several layers of filters.</h3>\n",
        "<ul>\n",
        "  <li>The convolution layers are generally followed by maxpool layers that are used to reduce the number of features extracted and ultimately the output of the maxpool and layers and convolution layers are flattened into a vector of single dimension and are given as an input to the Dense layer (The fully connected network).</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "NEEedl1cKcsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation =\"relu\"))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "model.add(Dense(26,activation =\"softmax\"))"
      ],
      "metadata": {
        "id": "a6wzOxjwItq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN model designed for training the model over the training dataset. We create a <code>Sequential</code> model.<br>\n",
        "<code>Conv2D()</code>: 2D convolution layer (e.g. spatial convolution over images.) This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
        "<ul>\n",
        "  <li><code>filters</code>: Integer, the dimensionality of the output space</li>\n",
        "  <li><code>kernel_size</code>: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</li>\n",
        "  <li><code>activation</code>: Activation function to use</li>\n",
        "  <li><code>padding</code>: one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. </li>\n",
        "</ul>\n",
        "<br>\n",
        "<code>MaxPooling2D()</code>: Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.\n",
        "<ul>\n",
        "  <li><code>pool_size</code>: integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.</li>\n",
        "  <li><code>strides</code>: Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.</li>\n",
        "</ul>\n",
        "\n",
        "<code>flatten()</code>: flattens the input. Does not affect the batch size. \n",
        "\n",
        "<code>Dense()</code>: densely connected NN layer. Dense layer is a neural network layer that is connected deeply, which means each neuron in the dense layer receives input from all neurons of its previous layer.\n",
        "<ul>\n",
        "  <li><code>units</code>: Positive integer, dimensionality of the output space.</li>\n",
        "  <li><code>activation</code>: Activation function to use.</li>\n",
        "</ul>\n",
        "\n",
        "> <b>Recall</b>: <code>tf.keras.activations.relu</code> activation applies the rectified linear unit activation function.\n",
        "\n",
        "> <b>Recall</b>: <code>tf.keras.activations.softmax</code> is an activation that convert a vector of values to a probability distribution.<br>"
      ],
      "metadata": {
        "id": "hmkUPU26MJtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Compiling and Fitting the Model<h1>\n",
        "<h4>The optimizing function used is Adam, that is a combination of RMSprop & Adagram optimizing algorithms.\n",
        "The dataset is very large so we are training for only a single epoch, however, as required we can even train it for multiple epochs(which is recommended for character recognition for better accuracy).</h4>\n"
      ],
      "metadata": {
        "id": "BVW6_Z-5Q6ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))"
      ],
      "metadata": {
        "id": "SUFuQMYELre0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.save(r'model_hand.h5')"
      ],
      "metadata": {
        "id": "w-XT98ETRBII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Getting the Train & Validation Accuracies & Losses.</h1>\n",
        "Training & validation accuracies along with the training & validation losses for character recognition."
      ],
      "metadata": {
        "id": "H8UdFyi6S9-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The validation accuracy is :\", history.history['val_accuracy'])\n",
        "print(\"The training accuracy is :\", history.history['accuracy'])\n",
        "print(\"The validation loss is :\", history.history['val_loss'])\n",
        "print(\"The training loss is :\", history.history['loss'])"
      ],
      "metadata": {
        "id": "5kQHWxiES67Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Doing Some Predictions on Test Data</h1>\n",
        "Create 9 subplots of (3,3) shape & visualize some of the test dataset alphabets along with their predictions, that are made using the <code>model.predict()</code> function for text recognition."
      ],
      "metadata": {
        "id": "GNYVm20vTM1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
        "axes = axes.flatten()\n",
        "for i,ax in enumerate(axes):\n",
        "    img = np.reshape(test_X[i], (28,28))\n",
        "    ax.imshow(img, cmap=\"Greys\")\n",
        "    \n",
        "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
        "    ax.set_title(\"Prediction: \"+pred)\n",
        "    ax.grid()"
      ],
      "metadata": {
        "id": "K2bIqKMwTKnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Doing Prediction on External Image</h1>\n",
        "Read an external image and make a copy of it to go through some processing. The image read is then converted from BGR representation (as OpenCV reads the image in BGR format) to RGB for displaying the image, & is resized to our required dimensions that we want to display the image in."
      ],
      "metadata": {
        "id": "3mlGdkIYrQtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(r'C:\\Users\\abhij\\Downloads\\img_b.jpg')\n",
        "img_copy = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400,440))"
      ],
      "metadata": {
        "id": "_3L8I8uxTRDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oUx8q5u7MTkU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}